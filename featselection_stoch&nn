#Program 10 – Feature Selection using Stochastic Optimization + Neural Network
import numpy as np
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier

# 1️⃣ Load image dataset (MNIST small subset)
X, y = fetch_openml('mnist_784', version=1, return_X_y=True, parser="pandas")
X, y = X[:2000], y[:2000].astype(int)
X = StandardScaler().fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
n_features = X.shape[1]

# 2️⃣ Evaluate neural network with selected features
def evaluate(features):
    if np.sum(features) == 0:
        return 0
    X_tr, X_te = X_train[:, features==1], X_test[:, features==1]
    model = MLPClassifier(hidden_layer_sizes=(64,), max_iter=100)
    model.fit(X_tr, y_train)
    return model.score(X_te, y_test)

# 3️⃣ Stochastic Optimization (Randomized Feature Search)
np.random.seed(42)
best_features = np.random.randint(0, 2, n_features)
best_acc = evaluate(best_features)

for i in range(20):
    new_features = best_features.copy()
    flip = np.random.randint(n_features)
    new_features[flip] ^= 1
    acc = evaluate(new_features)
    if acc > best_acc:
        best_features, best_acc = new_features, acc
    print(f"Iter {i+1}: Accuracy = {acc:.4f}, Best = {best_acc:.4f}")

# 4️⃣ Results
print("\n✅ Final Best Accuracy:", round(best_acc, 4))
print("✅ Selected Features:", np.sum(best_features), "out of", n_features)
